"""
Drift Metrics Exporter
======================

Reads drift report from pipeline and exposes metrics to Prometheus endpoint.

Usage:
    python expose_drift_stats.py
"""

import logging
import json
from pathlib import Path
from datetime import datetime, timezone

from metrics_utils import write_metrics_file, format_gauge

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [DRIFT-METRICS] %(message)s',
    handlers=[
        logging.FileHandler(Path(__file__).parent / 'drift_metrics.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

DRIFT_REPORT_PATH = Path('/home/jbhathen/group-project-f25-the-real-reel-deal/monitoring/drift_report.json')


def load_drift_report():
    """Load drift report generated by training pipeline."""
    if not DRIFT_REPORT_PATH.exists():
        logger.warning(f"Drift report not found: {DRIFT_REPORT_PATH}")
        logger.warning("Run training pipeline first to generate drift report")
        return None
    
    with open(DRIFT_REPORT_PATH, 'r') as f:
        report = json.load(f)
    
    timestamp = report.get('timestamp', 'unknown')
    logger.info(f"✓ Loaded drift report (created: {timestamp})")
    return report


def export_drift_metrics(drift_report):
    """Export drift metrics to Prometheus endpoint."""
    timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%d')
    
    metrics = {}
    
    # Overall drift detection
    metrics.update(format_gauge(
        'data_drift_detected',
        1.0 if drift_report['drift_detected'] else 0.0,
        labels={'date': timestamp}
    ))
    
    # Data volume metrics
    recent_size = drift_report['recent_data_size']
    baseline_size = drift_report['baseline_data_size']
    
    metrics.update(format_gauge(
        'data_drift_recent_data_size',
        recent_size,
        labels={'date': timestamp}
    ))
    
    metrics.update(format_gauge(
        'data_drift_baseline_data_size',
        baseline_size,
        labels={'date': timestamp}
    ))
    
    metrics.update(format_gauge(
        'data_drift_sample_size_ratio',
        recent_size / baseline_size if baseline_size > 0 else 0,
        labels={'date': timestamp}
    ))
    
    metrics.update(format_gauge(
        'data_drift_tests_performed_count',
        len(drift_report['tests_performed']),
        labels={'date': timestamp}
    ))
    
    # Rating distribution metrics
    if 'rating_distribution' in drift_report:
        rd = drift_report['rating_distribution']
        
        metrics.update(format_gauge(
            'data_drift_rating_pvalue', 
            rd['p_value'],
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_rating_ks_statistic',
            rd['ks_statistic'],
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_rating_detected',
            1.0 if rd['drift_detected'] else 0.0,
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_rating_mean_baseline',
            rd['baseline_mean'],
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_rating_mean_recent',
            rd['recent_mean'],
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_rating_mean_shift',
            rd['mean_shift'],
            labels={'date': timestamp}
        ))
        
        baseline_mean = rd['baseline_mean']
        if baseline_mean != 0:
            pct_shift = (rd['mean_shift'] / baseline_mean) * 100
            metrics.update(format_gauge(
                'data_drift_rating_mean_shift_pct',
                pct_shift,
                labels={'date': timestamp}
            ))
    
    # User activity metrics
    if 'user_activity' in drift_report:
        ua = drift_report['user_activity']
        
        metrics.update(format_gauge(
            'data_drift_user_activity_pvalue',
            ua['p_value'],
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_user_activity_ks_statistic',
            ua['ks_statistic'],
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_user_activity_detected',
            1.0 if ua['drift_detected'] else 0.0,
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_user_activity_mean_baseline',
            ua['baseline_mean'],
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_user_activity_mean_recent',
            ua['recent_mean'],
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_user_activity_mean_shift',
            ua['mean_shift'],
            labels={'date': timestamp}
        ))
        
        baseline_mean = ua['baseline_mean']
        if baseline_mean != 0:
            pct_shift = (ua['mean_shift'] / baseline_mean) * 100
            metrics.update(format_gauge(
                'data_drift_user_activity_mean_shift_pct',
                pct_shift,
                labels={'date': timestamp}
            ))
    
    # Movie popularity metrics
    if 'movie_popularity' in drift_report:
        mp = drift_report['movie_popularity']
        
        metrics.update(format_gauge(
            'data_drift_movie_popularity_psi',
            mp['psi'],
            labels={'date': timestamp}
        ))
        
        metrics.update(format_gauge(
            'data_drift_movie_popularity_detected',
            1.0 if mp['drift_detected'] else 0.0,
            labels={'date': timestamp}
        ))
        
        drift_level_map = {
            'no_drift': 0,
            'moderate_drift': 1,
            'significant_drift': 2
        }
        metrics.update(format_gauge(
            'data_drift_movie_popularity_level',
            drift_level_map.get(mp['drift_level'], 0),
            labels={'date': timestamp}
        ))
    
    write_metrics_file(metrics)
    logger.info(f"✓ Exported {len(metrics)} drift metrics")


def main():
    logger.info("=" * 70)
    logger.info("DRIFT METRICS EXPORTER")
    logger.info("=" * 70)
    
    drift_report = load_drift_report()
    if drift_report is None:
        logger.error("No drift report available")
        return
    
    export_drift_metrics(drift_report)
    
    logger.info("=" * 70)
    if drift_report['drift_detected']:
        logger.warning("⚠️  Drift detected:")
        for issue in drift_report['drift_summary']:
            logger.warning(f"   - {issue}")
    else:
        logger.info("✓ No drift detected")
    logger.info("=" * 70)


if __name__ == '__main__':
    main()